apiVersion: v1
kind: Namespace
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    openshift.io/display-name: NVIDIA GPU Operator
  labels:
    openshift.io/cluster-monitoring: "true"
  name: nvidia-gpu-operator
---
apiVersion: v1
kind: Namespace
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    openshift.io/display-name: Node Feature Discovery Operator
  labels:
    openshift.io/cluster-monitoring: "true"
  name: openshift-nfd
---
apiVersion: v1
kind: Namespace
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    openshift.io/display-name: Red Hat OpenShift Serverless
  labels:
    openshift.io/cluster-monitoring: "true"
  name: openshift-serverless
---
apiVersion: v1
kind: Namespace
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
    openshift.io/display-name: OpenShift AI - Main Applications
  labels:
    openshift.io/cluster-monitoring: "true"
  name: redhat-ods-applications
---
apiVersion: v1
kind: Namespace
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
    openshift.io/display-name: OpenShift AI - Monitoring
  labels:
    openshift.io/cluster-monitoring: "true"
  name: redhat-ods-monitoring
---
apiVersion: v1
kind: Namespace
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    openshift.io/display-name: Red Hat OpenShift AI
  labels:
    openshift.io/cluster-monitoring: "true"
  name: redhat-ods-operator
---
apiVersion: v1
kind: Namespace
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
    openshift.io/display-name: OpenShift AI - Individual Notebooks
  labels:
    openshift.io/cluster-monitoring: "true"
  name: rhods-notebooks
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-aws-gpu-machineset
  namespace: nvidia-gpu-operator
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    autoscale: config
  name: job-setup-machineset
  namespace: openshift-machine-api
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-pipelines-console-plugin
  namespace: openshift-operators
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: fix-dashboard-magic
  namespace: redhat-ods-applications
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: approve-after-servicemesh
  namespace: redhat-ods-operator
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: wait-for-servicemesh
  namespace: redhat-ods-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: fix-dashboard-magic
  namespace: redhat-ods-applications
rules:
- apiGroups:
  - apps
  resourceNames:
  - rhods-dashboard
  resources:
  - deployments
  - deployments/scale
  verbs:
  - get
  - list
  - patch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - delete
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: approve-after-servicemesh
rules:
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - get
  - list
- apiGroups:
  - operators.coreos.com
  resources:
  - subscriptions
  - installplans
  verbs:
  - get
  - list
  - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-aws-gpu-machineset
rules:
- apiGroups:
  - machine.openshift.io
  resources:
  - machinesets
  verbs:
  - '*'
- apiGroups:
  - autoscaling.openshift.io
  resources:
  - machineautoscalers
  verbs:
  - '*'
- apiGroups:
  - ""
  resourceNames:
  - aws-creds
  resources:
  - secrets
  verbs:
  - get
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-gpu-console-plugin
rules:
- apiGroups:
  - operator.openshift.io
  resources:
  - consoles
  verbs:
  - get
  - list
  - patch
  - label
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-pipelines-console-plugin
rules:
- apiGroups:
  - operator.openshift.io
  resources:
  - consoles
  verbs:
  - get
  - list
  - patch
  - label
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    autoscale: config
  name: job-setup-machineset
rules:
- apiGroups:
  - machine.openshift.io
  resources:
  - machinesets
  verbs:
  - '*'
- apiGroups:
  - autoscaling.openshift.io
  resources:
  - machineautoscalers
  verbs:
  - '*'
- apiGroups:
  - ""
  resourceNames:
  - aws-creds
  resources:
  - secrets
  verbs:
  - get
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: wait-for-servicemesh
rules:
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - get
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: fix-dashboard-magic
  namespace: redhat-ods-applications
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: fix-dashboard-magic
subjects:
- kind: ServiceAccount
  name: fix-dashboard-magic
  namespace: redhat-ods-applications
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: approve-after-servicemesh
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: approve-after-servicemesh
subjects:
- kind: ServiceAccount
  name: approve-after-servicemesh
  namespace: redhat-ods-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: fix-rhoai-kubeadmin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: User
  name: kube:admin
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-aws-gpu-machineset
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: job-aws-gpu-machineset
subjects:
- kind: ServiceAccount
  name: job-aws-gpu-machineset
  namespace: nvidia-gpu-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-gpu-console-plugin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: job-gpu-console-plugin
subjects:
- kind: ServiceAccount
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-pipelines-console-plugin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: job-pipelines-console-plugin
subjects:
- kind: ServiceAccount
  name: job-pipelines-console-plugin
  namespace: openshift-operators
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    autoscale: config
  name: job-setup-machineset
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: job-setup-machineset
subjects:
- kind: ServiceAccount
  name: job-setup-machineset
  namespace: openshift-machine-api
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: wait-for-servicemesh
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: wait-for-servicemesh
subjects:
- kind: ServiceAccount
  name: wait-for-servicemesh
  namespace: redhat-ods-operator
---
apiVersion: v1
data:
  dcgm-metrics.csv: |
    # see https://github.com/NVIDIA/dcgm-exporter/blob/main/etc/dcp-metrics-included.csv
    DCGM_FI_PROF_GR_ENGINE_ACTIVE, gauge, gpu utilization.
    DCGM_FI_DEV_MEM_COPY_UTIL, gauge, mem utilization.
    DCGM_FI_DEV_ENC_UTIL, gauge, enc utilization.
    DCGM_FI_DEV_DEC_UTIL, gauge, dec utilization.
    DCGM_FI_DEV_FB_FREE, gauge, mem free.
    DCGM_FI_DEV_FB_USED, gauge, mem used.
    DCGM_FI_DEV_GPU_UTIL, gauge, gpu utilization.
    DCGM_FI_DEV_POWER_USAGE, gauge, power usage.
    DCGM_FI_DEV_POWER_MGMT_LIMIT_MAX, gauge, power mgmt limit.
    DCGM_FI_DEV_GPU_TEMP, gauge, gpu temp.
    DCGM_FI_DEV_SM_CLOCK, gauge, sm clock.
    DCGM_FI_DEV_MAX_SM_CLOCK, gauge, max sm clock.
    DCGM_FI_DEV_MEM_CLOCK, gauge, mem clock.
    DCGM_FI_DEV_MAX_MEM_CLOCK, gauge, max mem clock.
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
---
apiVersion: v1
data:
  no-time-sliced: 'version: v1'
  time-sliced: |-
    version: v1
    sharing:
      timeSlicing:
        resources:
          - name: nvidia.com/gpu
            replicas: 2
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: device-plugin-config
  namespace: nvidia-gpu-operator
---
apiVersion: v1
data:
  job.sh: |
    #!/bin/bash

    # shellcheck disable=SC1091
    . /scripts/ocp.sh

    INSTANCE_TYPE=${INSTANCE_TYPE:-g4dn.4xlarge}

    ocp_aws_cluster || exit 0
    ocp_aws_machineset_create_gpu "${INSTANCE_TYPE}"
    ocp_machineset_create_autoscale
    ocp_aws_machineset_fix_storage
    # ocp_machineset_taint_gpu
  ocp.sh: |
    #!/bin/bash
    # shellcheck disable=SC2120

    # See https://github.com/redhat-na-ssa/demo-ai-gitops-catalog
    # FUNCTIONS='
    # ocp_aws_cluster
    # ocp_aws_machineset_create_gpu
    # ocp_aws_machineset_clone_worker
    # ocp_aws_machineset_fix_storage
    # ocp_machineset_create_autoscale
    # ocp_machineset_taint_gpu
    # '

    # for function in ${FUNCTIONS}
    # do
    #   extract_function $function scripts/library/ocp.sh >> tmp
    #   echo >> tmp
    # done

    ocp_aws_cluster(){
      TARGET_NS=kube-system
      OBJ=secret/aws-creds
      echo "Checking if ${OBJ} exists in ${TARGET_NS} namespace"
      oc -n "${TARGET_NS}" get "${OBJ}" -o name > /dev/null 2>&1 || return 1
      echo "AWS cluster detected"
    }

    ocp_aws_machineset_create_gpu(){
      # https://aws.amazon.com/ec2/instance-types/g4
      # single gpu: g4dn.{2,4,8,16}xlarge
      # multi gpu:  g4dn.12xlarge
      # practical:  g4ad.4xlarge
      # a100 (MIG): p4d.24xlarge
      # h100 (MIG): p5.48xlarge

      # https://aws.amazon.com/ec2/instance-types/dl1
      # 8 x gaudi:  dl1.24xlarge

      INSTANCE_TYPE=${1:-g4dn.4xlarge}

      ocp_aws_machineset_clone_worker "${INSTANCE_TYPE}"

      MACHINE_SET_TYPE=$(oc -n openshift-machine-api get machinesets.machine.openshift.io -o name | grep "${INSTANCE_TYPE%.*}" | head -n1)

      echo "Patching: ${MACHINE_SET_TYPE}"

      # cosmetic
      oc -n openshift-machine-api \
        patch "${MACHINE_SET_TYPE}" \
        --type=merge --patch '{"spec":{"template":{"spec":{"metadata":{"labels":{"node-role.kubernetes.io/gpu":""}}}}}}'

      # should use the default profile
      # oc -n openshift-machine-api \
      #   patch "${MACHINE_SET_TYPE}" \
      #   --type=merge --patch '{"spec":{"template":{"spec":{"metadata":{"labels":{"nvidia.com/device-plugin.config":"no-time-sliced"}}}}}}'

      # should help auto provisioner
      oc -n openshift-machine-api \
        patch "${MACHINE_SET_TYPE}" \
        --type=merge --patch '{"spec":{"template":{"spec":{"metadata":{"labels":{"cluster-api/accelerator":"nvidia-gpu"}}}}}}'

      oc -n openshift-machine-api \
        patch "${MACHINE_SET_TYPE}" \
        --type=merge --patch '{"metadata":{"labels":{"cluster-api/accelerator":"nvidia-gpu"}}}'

      oc -n openshift-machine-api \
        patch "${MACHINE_SET_TYPE}" \
        --type=merge --patch '{"spec":{"template":{"spec":{"providerSpec":{"value":{"instanceType":"'"${INSTANCE_TYPE}"'"}}}}}}'

    #  # fix storage

    # cat << YAML > /tmp/patch.yaml
    # spec:
    #   template:
    #     spec:
    #       providerSpec:
    #         value:
    #           blockDevices:
    #             - ebs:
    #                 volumeSize: 120
    #                 volumeType: gp3
    # YAML

    #   oc -n openshift-machine-api \
    #     patch "${MACHINE_SET_TYPE}" \
    #     --type=merge --patch "$(cat /tmp/patch.yaml)"
    }

    ocp_aws_machineset_clone_worker(){
      [ -z "${1}" ] && \
      echo "
        usage: ocp_aws_machineset_clone_worker < instance type, default g4dn.4xlarge > < machine set name >
      "

      INSTANCE_TYPE=${1:-g4dn.4xlarge}
      SHORT_NAME=${2:-${INSTANCE_TYPE/./-}}

      MACHINE_SET_NAME=$(oc -n openshift-machine-api get machinesets.machine.openshift.io -o name | grep "${SHORT_NAME}" | head -n1)
      MACHINE_SET_WORKER=$(oc -n openshift-machine-api get machinesets.machine.openshift.io -o name | grep worker | head -n1)

      # check for an existing instance machine set
      if [ -n "${MACHINE_SET_NAME}" ]; then
        echo "Exists: machineset - ${MACHINE_SET_NAME}"
      else
        echo "Creating: machineset - ${SHORT_NAME}"
        oc -n openshift-machine-api \
          get "${MACHINE_SET_WORKER}" -o yaml | \
            sed '/machine/ s/'"${MACHINE_SET_WORKER##*/}"'/'"${SHORT_NAME}"'/g
              /^  name:/ s/'"${MACHINE_SET_WORKER##*/}"'/'"${SHORT_NAME}"'/g
              /name/ s/'"${MACHINE_SET_WORKER##*/}"'/'"${SHORT_NAME}"'/g
              s/instanceType.*/instanceType: '"${INSTANCE_TYPE}"'/
              /cluster-api-autoscaler/d
              /uid:/d
              /generation:/d
              /resourceVersion:/d
              /creationTimestamp:/d
              s/replicas.*/replicas: 0/' | \
          oc apply -f -
      fi

      # fix aws storage
      ocp_aws_machineset_fix_storage "${MACHINE_SET_NAME}"

      # cosmetic pretty
      oc -n openshift-machine-api \
        patch "${MACHINE_SET_NAME}" \
        --type=merge --patch '{"spec":{"template":{"spec":{"metadata":{"labels":{"node-role.kubernetes.io/'"${SHORT_NAME}"'":""}}}}}}'
    }

    ocp_aws_machineset_fix_storage(){
      MACHINE_SETS=${1:-$(oc -n openshift-machine-api get machineset -o name)}
      HD_SIZE=200

      for machine_set in ${MACHINE_SETS}
      do
        echo "Patching aws storage for machineset: ${machine_set}"
        oc -n openshift-machine-api \
          get "${machine_set}" -o yaml | \
            sed 's/volumeSize: 100/volumeSize: '"${HD_SIZE}"'/
              s/volumeType: gp2/volumeType: gp3/' | \
          oc apply -f -
      done
    }

    ocp_machineset_create_autoscale(){
      MACHINE_MIN=${1:-0}
      MACHINE_MAX=${2:-4}
      MACHINE_SETS=${3:-$(oc -n openshift-machine-api get machinesets.machine.openshift.io -o name | sed 's@.*/@@' )}

      for machine_set in ${MACHINE_SETS}
      do
    cat << YAML | oc apply -f -
    apiVersion: "autoscaling.openshift.io/v1beta1"
    kind: "MachineAutoscaler"
    metadata:
      name: "${machine_set}"
      namespace: "openshift-machine-api"
    spec:
      minReplicas: ${MACHINE_MIN}
      maxReplicas: ${MACHINE_MAX}
      scaleTargetRef:
        apiVersion: machine.openshift.io/v1beta1
        kind: MachineSet
        name: "${machine_set}"
    YAML
      done
    }

    ocp_machineset_taint_gpu(){
      SHORT_NAME=${1:-g4dn}
      MACHINE_SET=$(oc -n openshift-machine-api get machinesets.machine.openshift.io -o name | grep "${SHORT_NAME}" | head -n1)

      echo "Patching: ${MACHINE_SET}"

      # taint nodes for gpu-only workloads
      oc -n openshift-machine-api \
        patch "${MACHINE_SET}" \
        --type=merge --patch '{"spec":{"template":{"spec":{"taints":[{"key":"nvidia.com/gpu","value":"","effect":"NoSchedule"}]}}}}'
    }
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-aws-gpu-machineset
  namespace: nvidia-gpu-operator
---
apiVersion: v1
data:
  console-plugin-job.sh: |
    #!/usr/bin/bash

    enable_console_plugin(){
      [ -z "${PLUGIN_NAME}" ] && return 1

      echo "Attempting to enable ${PLUGIN_NAME} plugin"
      echo ""

      # Create the plugins section on the object if it doesn't exist
      if [ -z "$(oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}')" ]; then
        echo "Creating plugins object"
        oc patch consoles.operator.openshift.io cluster --patch '{ "spec": { "plugins": [] } }' --type=merge
      fi

      INSTALLED_PLUGINS=$(oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}')
      echo "Current plugins:"
      echo "${INSTALLED_PLUGINS}"

      if [[ "${INSTALLED_PLUGINS}" == *"${PLUGIN_NAME}"* ]]; then
          echo "${PLUGIN_NAME} is already enabled"
      else
          echo "Enabling plugin: ${PLUGIN_NAME}"
          oc patch consoles.operator.openshift.io cluster --type=json --patch '[{"op": "add", "path": "/spec/plugins/-", "value": "'"${PLUGIN_NAME}"'"}]'
      fi

      sleep 6
      oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}'
    }

    enable_console_plugin
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
---
apiVersion: v1
data:
  dcgm-exporter-dashboard.json: |
    {
      "__requires": [
        {
          "type": "panel",
          "id": "gauge",
          "name": "Gauge",
          "version": ""
        },
        {
          "type": "grafana",
          "id": "grafana",
          "name": "Grafana",
          "version": "6.7.3"
        },
        {
          "type": "panel",
          "id": "graph",
          "name": "Graph",
          "version": ""
        },
        {
          "type": "datasource",
          "id": "prometheus",
          "name": "Prometheus",
          "version": "1.0.0"
        }
      ],
      "annotations": {
        "list": [
          {
            "$$hashKey": "object:192",
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "description": "This dashboard is to display the metrics from DCGM Exporter on a Kubernetes (1.19+) cluster",
      "editable": true,
      "gnetId": 12239,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1588401887165,
      "links": [],
      "panels": [
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "$datasource",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 18,
            "x": 0,
            "y": 0
          },
          "hiddenSeries": false,
          "id": 12,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": false,
            "rightSide": true,
            "show": true,
            "total": false,
            "values": true
          },
          "lines": true,
          "linewidth": 2,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "DCGM_FI_DEV_GPU_TEMP{instance=~\"$instance\", gpu=~\"$gpu\"}",
              "instant": false,
              "interval": "",
              "legendFormat": "GPU {{gpu}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "GPU Temperature",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "celsius",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "datasource": "$datasource",
          "gridPos": {
            "h": 8,
            "w": 6,
            "x": 18,
            "y": 0
          },
          "id": 14,
          "options": {
            "fieldOptions": {
              "calcs": [
                "mean"
              ],
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 100,
                "min": 0,
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "#EAB839",
                      "value": 83
                    },
                    {
                      "color": "red",
                      "value": 87
                    }
                  ]
                },
                "unit": "celsius"
              },
              "overrides": [],
              "values": false
            },
            "orientation": "auto",
            "showThresholdLabels": false,
            "showThresholdMarkers": true
          },
          "pluginVersion": "6.7.3",
          "targets": [
            {
              "expr": "avg(DCGM_FI_DEV_GPU_TEMP{instance=~\"$instance\", gpu=~\"$gpu\"})",
              "interval": "",
              "legendFormat": "",
              "refId": "A"
            }
          ],
          "timeFrom": null,
          "timeShift": null,
          "title": "GPU Avg. Temp",
          "type": "gauge"
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "$datasource",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 18,
            "x": 0,
            "y": 8
          },
          "hiddenSeries": false,
          "id": 10,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": false,
            "rightSide": true,
            "show": true,
            "total": false,
            "values": true
          },
          "lines": true,
          "linewidth": 2,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pluginVersion": "6.5.2",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "DCGM_FI_DEV_POWER_USAGE{instance=~\"$instance\", gpu=~\"$gpu\"}",
              "interval": "",
              "legendFormat": "GPU {{gpu}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "GPU Power Usage",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "watt",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "cacheTimeout": null,
          "datasource": "$datasource",
          "gridPos": {
            "h": 8,
            "w": 6,
            "x": 18,
            "y": 8
          },
          "id": 16,
          "links": [],
          "options": {
            "fieldOptions": {
              "calcs": [
                "sum"
              ],
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "max": 2400,
                "min": 0,
                "nullValueMode": "connected",
                "thresholds": {
                  "mode": "absolute",
                  "steps": [
                    {
                      "color": "green",
                      "value": null
                    },
                    {
                      "color": "#EAB839",
                      "value": 1800
                    },
                    {
                      "color": "red",
                      "value": 2200
                    }
                  ]
                },
                "unit": "watt"
              },
              "overrides": [],
              "values": false
            },
            "orientation": "horizontal",
            "showThresholdLabels": false,
            "showThresholdMarkers": true
          },
          "pluginVersion": "6.7.3",
          "targets": [
            {
              "expr": "sum(DCGM_FI_DEV_POWER_USAGE{instance=~\"$instance\", gpu=~\"$gpu\"})",
              "instant": true,
              "interval": "",
              "legendFormat": "",
              "range": false,
              "refId": "A"
            }
          ],
          "timeFrom": null,
          "timeShift": null,
          "title": "GPU Power Total",
          "type": "gauge"
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "$datasource",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 16
          },
          "hiddenSeries": false,
          "id": 2,
          "interval": "",
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": false,
            "rightSide": true,
            "show": true,
            "sideWidth": null,
            "total": false,
            "values": true
          },
          "lines": true,
          "linewidth": 2,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "DCGM_FI_DEV_SM_CLOCK{instance=~\"$instance\", gpu=~\"$gpu\"} * 1000000",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "GPU {{gpu}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "GPU SM Clocks",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "decimals": null,
              "format": "hertz",
              "label": "",
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "$datasource",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 24
          },
          "hiddenSeries": false,
          "id": 6,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": false,
            "rightSide": true,
            "show": true,
            "total": false,
            "values": true
          },
          "lines": true,
          "linewidth": 2,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "DCGM_FI_DEV_GPU_UTIL{instance=~\"$instance\", gpu=~\"$gpu\"}",
              "interval": "",
              "legendFormat": "GPU {{gpu}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "GPU Utilization",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "cumulative"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "percent",
              "label": null,
              "logBase": 1,
              "max": "100",
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "$datasource",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 32
          },
          "hiddenSeries": false,
          "id": 18,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": false,
            "rightSide": true,
            "show": true,
            "total": false,
            "values": true
          },
          "lines": true,
          "linewidth": 2,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "DCGM_FI_DEV_FB_USED{instance=~\"$instance\", gpu=~\"$gpu\"}",
              "interval": "",
              "legendFormat": "GPU {{gpu}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "GPU Framebuffer Mem Used",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "decmbytes",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "$datasource",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 24
          },
          "hiddenSeries": false,
          "id": 4,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": false,
            "rightSide": true,
            "show": true,
            "total": false,
            "values": true
          },
          "lines": true,
          "linewidth": 2,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "DCGM_FI_PROF_PIPE_TENSOR_ACTIVE{instance=~\"$instance\", gpu=~\"$gpu\"}",
              "interval": "",
              "legendFormat": "GPU {{gpu}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Tensor Core Utilization",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "cumulative"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "percentunit",
              "label": null,
              "logBase": 1,
              "max": "1",
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        }
      ],
      "refresh": false,
      "schemaVersion": 22,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {
              "selected": true,
              "text": "Prometheus",
              "value": "Prometheus"
            },
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "datasource",
            "options": [],
            "query": "prometheus",
            "queryValue": "",
            "refresh": 1,
            "regex": "",
            "skipUrlSync": false,
            "type": "datasource"
          },
          {
            "allValue": null,
            "current": {},
            "datasource": "$datasource",
            "definition": "label_values(DCGM_FI_DEV_GPU_TEMP, instance)",
            "hide": 0,
            "includeAll": true,
            "index": -1,
            "label": null,
            "multi": true,
            "name": "instance",
            "options": [],
            "query": "label_values(DCGM_FI_DEV_GPU_TEMP, instance)",
            "refresh": 1,
            "regex": "",
            "skipUrlSync": false,
            "sort": 1,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          },
          {
            "allValue": null,
            "current": {},
            "datasource": "$datasource",
            "definition": "label_values(DCGM_FI_DEV_GPU_TEMP, gpu)",
            "hide": 0,
            "includeAll": true,
            "index": -1,
            "label": null,
            "multi": true,
            "name": "gpu",
            "options": [],
            "query": "label_values(DCGM_FI_DEV_GPU_TEMP, gpu)",
            "refresh": 1,
            "regex": "",
            "skipUrlSync": false,
            "sort": 1,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {
        "refresh_intervals": [
          "5s",
          "10s",
          "30s",
          "1m",
          "5m",
          "15m",
          "30m",
          "1h",
          "2h",
          "1d"
        ]
      },
      "timezone": "",
      "title": "NVIDIA DCGM Exporter Dashboard",
      "uid": "Oxed_c6Wz",
      "variables": {
        "list": []
      },
      "version": 1
    }
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    console.openshift.io/dashboard: "true"
    console.openshift.io/odc-dashboard: "true"
  name: nvidia-dcgm-exporter-dashboard
  namespace: openshift-config-managed
---
apiVersion: v1
data:
  job.sh: |
    #!/bin/bash
    # shellcheck disable=SC1091

    . /scripts/ocp.sh

    ocp_machineset_create_autoscale "${MACHINE_MIN}" "${MACHINE_MAX}"
  ocp.sh: "#!/bin/bash\n\n# https://mirror.openshift.com/pub/openshift-v4\n\nocp_check_login(){\n
    \ oc whoami || return 1\n  oc cluster-info | head -n1\n  echo\n}\n\nocp_check_info(){\n
    \ echo \"== OCP INFO ==\"\n  ocp_check_login || return 1\n\n  echo \"NAMESPACE:
    $(oc project -q)\"\n  sleep \"${SLEEP_SECONDS:-8}\"\n}\n\nocp_kubeadmin_create(){\n
    \ PASS=${1:-$(genpass 5 )-$(genpass 5 )-$(genpass 5 )-$(genpass 5 )}\n\n  which
    htpasswd >/dev/null || return 1\n\n  HTPASSWD=$(htpasswd -nbB -C10 null \"${PASS}\")\n
    \ HASH=${HTPASSWD##*:}\n\n  echo \"\n  PASSWORD: ${PASS}\n  HASH:     ${HASH}\n\n
    \ oc apply -f scratch/kubeadmin.yaml\n  \"\n\ncat << YAML > scratch/kubeadmin.yaml\nkind:
    Secret\napiVersion: v1\nmetadata:\n  name: kubeadmin\n  namespace: kube-system\nstringData:\n
    \ kubeadmin: ${HASH}\n  password: ${PASS}\ntype: Opaque\nYAML\n}\n\nocp_kubeadmin_remove(){\n
    \ FORCE=${1:-No}\n\n  if [ \"${FORCE}\" = \"YES\" ]; then\n    [ ! -e scratch/kubeadmin.yaml
    ] && \\\n      oc get secret kubeadmin -n kube-system -o yaml > scratch/kubeadmin.yaml
    || return 1\n    oc delete secret kubeadmin -n kube-system\n  else\n    echo -e
    \"${RED}\n    WARNING: you must run - ocp_remove_kubeadmin YES\n\n    WARNING:
    you will lose access to your cluster if you do not\n      have a way to login
    to your cluster without kubeadmin. \n      \n      Examples:\n        - An identity
    provider with a cluster-admin user setup\n        - A kubeconfig file\n    ${NC}\"\n
    \   return\n  fi\n}\n\nocp_get_apps_domain(){\n  oc get ingresses.config.openshift.io
    cluster -o jsonpath='{.spec.domain}'\n}\n\nocp_aws_cluster(){\n  TARGET_NS=kube-system\n
    \ OBJ=secret/aws-creds\n  echo \"Checking if ${OBJ} exists in ${TARGET_NS} namespace\"\n
    \ oc -n \"${TARGET_NS}\" get \"${OBJ}\" -o name > /dev/null 2>&1 || return 1\n
    \ echo \"AWS cluster detected\"\n}\n\nocp_aws_get_key(){\n  # get aws creds\n
    \ ocp_aws_cluster || return 1\n\n  AWS_ACCESS_KEY_ID=$(oc -n kube-system extract
    secret/aws-creds --keys=aws_access_key_id --to=-)\n  AWS_SECRET_ACCESS_KEY=$(oc
    -n kube-system extract secret/aws-creds --keys=aws_secret_access_key --to=-)\n
    \ AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-2}\n\n  export AWS_ACCESS_KEY_ID\n
    \ export AWS_SECRET_ACCESS_KEY\n  export AWS_DEFAULT_REGION\n\n  echo \"AWS_DEFAULT_REGION:
    ${AWS_DEFAULT_REGION}\"\n}\n\nocp_aws_setup_ack_system(){\n  NAMESPACE=ack-system\n\n
    \ ocp_aws_get_key\n\n  setup_namespace ${NAMESPACE}\n\n  oc apply -k \"${GIT_ROOT}\"/components/operators/${NAMESPACE}/aggregate/popular\n\n
    \ for type in ec2 ecr iam lambda route53 s3 sagemaker\n  do\n\n    oc apply -k
    \"${GIT_ROOT}\"/components/operators/ack-${type}-controller/operator/overlays/alpha\n\n
    \   if oc -n \"${NAMESPACE}\" get secret \"${type}-user-secrets\" -o name; then\n
    \     echo \"Found: ${type}-user-secrets - not replacing\"\n      continue\n    fi\n\n
    \   < \"${GIT_ROOT}\"/components/operators/ack-${type}-controller/operator/overlays/alpha/user-secrets-secret.yaml
    \\\n      sed \"s@UPDATE_AWS_ACCESS_KEY_ID@${AWS_ACCESS_KEY_ID}@; s@UPDATE_AWS_SECRET_ACCESS_KEY@${AWS_SECRET_ACCESS_KEY}@\"
    | \\\n      oc -n ${NAMESPACE} apply -f -\n  done\n}\n\nocp_aws_machineset_clone_worker(){\n
    \ [ -z \"${1}\" ] && \\\n  echo \"\n    usage: ocp_aws_machineset_clone_worker
    < instance type, default g4dn.4xlarge > < machine set name >\n  \"\n\n  INSTANCE_TYPE=${1:-g4dn.4xlarge}\n
    \ SHORT_NAME=${2:-${INSTANCE_TYPE/./-}}\n\n  MACHINE_SET_NAME=$(oc -n openshift-machine-api
    get machinesets.machine.openshift.io -o name | grep \"${SHORT_NAME}\" | head -n1)\n
    \ MACHINE_SET_WORKER=$(oc -n openshift-machine-api get machinesets.machine.openshift.io
    -o name | grep worker | head -n1)\n\n  # check for an existing instance machine
    set\n  if [ -n \"${MACHINE_SET_NAME}\" ]; then\n    echo \"Exists: machineset
    - ${MACHINE_SET_NAME}\"\n  else\n    echo \"Creating: machineset - ${SHORT_NAME}\"\n
    \   oc -n openshift-machine-api \\\n      get \"${MACHINE_SET_WORKER}\" -o yaml
    | \\\n        sed '/machine/ s/'\"${MACHINE_SET_WORKER##*/}\"'/'\"${SHORT_NAME}\"'/g\n
    \         /^  name:/ s/'\"${MACHINE_SET_WORKER##*/}\"'/'\"${SHORT_NAME}\"'/g\n
    \         /name/ s/'\"${MACHINE_SET_WORKER##*/}\"'/'\"${SHORT_NAME}\"'/g\n          s/instanceType.*/instanceType:
    '\"${INSTANCE_TYPE}\"'/\n          /cluster-api-autoscaler/d\n          /uid:/d\n
    \         /generation:/d\n          /resourceVersion:/d\n          /creationTimestamp:/d\n
    \         s/replicas.*/replicas: 0/' | \\\n      oc apply -f -\n  fi\n\n  # fix
    aws storage\n  ocp_aws_machineset_fix_storage \"${MACHINE_SET_NAME}\"\n\n  # cosmetic
    pretty\n  oc -n openshift-machine-api \\\n    patch \"${MACHINE_SET_NAME}\" \\\n
    \   --type=merge --patch '{\"spec\":{\"template\":{\"spec\":{\"metadata\":{\"labels\":{\"node-role.kubernetes.io/'\"${SHORT_NAME}\"'\":\"\"}}}}}}'\n}\n\nocp_aws_machineset_fix_storage(){\n
    \ MACHINE_SETS=${1:-$(oc -n openshift-machine-api get machineset -o name)}\n  HD_SIZE=200\n\n
    \ for machine_set in ${MACHINE_SETS}\n  do\n    echo \"Patching aws storage for
    machineset: ${machine_set}\"\n    oc -n openshift-machine-api \\\n      get \"${machine_set}\"
    -o yaml | \\\n        sed 's/volumeSize: 100/volumeSize: '\"${HD_SIZE}\"'/\n          s/volumeType:
    gp2/volumeType: gp3/' | \\\n      oc apply -f -\n  done\n}\n\nocp_aws_create_odf_machineset(){\n
    \ INSTANCE_TYPE=${1:-m6a.2xlarge}\n  SHORT_NAME=${2:-odf-infra}\n\n  ocp_aws_machineset_clone_worker
    \"${INSTANCE_TYPE}\" \"${SHORT_NAME}\"\n\n  MACHINE_SET_NAME=$(oc -n openshift-machine-api
    get machinesets.machine.openshift.io -o name | grep \"${SHORT_NAME}\" | head -n1)\n\n
    \ echo \"Patching: ${MACHINE_SET_NAME}\"\n\ncat << YAML > /tmp/patch.yaml\nspec:\n
    \ replicas: 3\n  template:\n    spec:\n      taints:\n        - key: node.ocs.openshift.io/storage\n
    \         value: 'true'\n          effect: NoSchedule\n      metadata:\n        labels:\n
    \         cluster.ocs.openshift.io/openshift-storage: ''\n          node-role.kubernetes.io/infra:
    ''\n      providerSpec:\n        value:\n          blockDevices:\n            -
    ebs:\n                encrypted: true\n                iops: 0\n                kmsKey:\n
    \                 arn: ''\n                volumeSize: 100\n                volumeType:
    gp3\n            # - deviceName: /dev/xvdb\n            #   ebs:\n            #
    \    encrypted: true\n            #     iops: 0\n            #     kmsKey:\n            #
    \      arn: ''\n            #     volumeSize: 1000\n            #     volumeType:
    gp3\nYAML\n\n  # patch storage\n  oc -n openshift-machine-api \\\n    patch \"${MACHINE_SET_NAME}\"
    \\\n    --type=merge --patch \"$(cat /tmp/patch.yaml)\"\n\n}\n\nocp_aws_machineset_create_metal(){\n
    \ # https://aws.amazon.com/ec2/instance-types/m5zn\n  # m5.metal\n  # m5n.metal\n\n
    \ INSTANCE_TYPE=${1:-m5n.metal}\n\n  ocp_aws_machineset_clone_worker \"${INSTANCE_TYPE}\"\n\n
    \ MACHINE_SET_TYPE=$(oc -n openshift-machine-api get machinesets.machine.openshift.io
    -o name | grep \"${INSTANCE_TYPE%.*}\" | head -n1)\n\n  echo \"Patching: ${MACHINE_SET_TYPE}\"\n\n
    \ # cosmetic\n  oc -n openshift-machine-api \\\n    patch \"${MACHINE_SET_TYPE}\"
    \\\n    --type=merge --patch '{\"spec\":{\"template\":{\"spec\":{\"metadata\":{\"labels\":{\"node-role.kubernetes.io/metal\":\"\"}}}}}}'\n\n
    \ oc -n openshift-machine-api \\\n    patch \"${MACHINE_SET_TYPE}\" \\\n    --type=merge
    --patch '{\"spec\":{\"template\":{\"spec\":{\"providerSpec\":{\"value\":{\"instanceType\":\"'\"${INSTANCE_TYPE}\"'\"}}}}}}'\n}\n\nocp_aws_machineset_create_gpu(){\n
    \ # https://aws.amazon.com/ec2/instance-types/g4\n  # single gpu: g4dn.{2,4,8,16}xlarge\n
    \ # multi gpu:  g4dn.12xlarge\n  # practical:  g4ad.4xlarge\n  # a100 (MIG): p4d.24xlarge\n
    \ # h100 (MIG): p5.48xlarge\n\n  # https://aws.amazon.com/ec2/instance-types/dl1\n
    \ # 8 x gaudi:  dl1.24xlarge\n\n  INSTANCE_TYPE=${1:-g4dn.4xlarge}\n\n  ocp_aws_machineset_clone_worker
    \"${INSTANCE_TYPE}\"\n\n  MACHINE_SET_TYPE=$(oc -n openshift-machine-api get machinesets.machine.openshift.io
    -o name | grep \"${INSTANCE_TYPE%.*}\" | head -n1)\n\n  echo \"Patching: ${MACHINE_SET_TYPE}\"\n\n
    \ # cosmetic\n  oc -n openshift-machine-api \\\n    patch \"${MACHINE_SET_TYPE}\"
    \\\n    --type=merge --patch '{\"spec\":{\"template\":{\"spec\":{\"metadata\":{\"labels\":{\"node-role.kubernetes.io/gpu\":\"\"}}}}}}'\n\n
    \ # should use the default profile\n  # oc -n openshift-machine-api \\\n  #   patch
    \"${MACHINE_SET_TYPE}\" \\\n  #   --type=merge --patch '{\"spec\":{\"template\":{\"spec\":{\"metadata\":{\"labels\":{\"nvidia.com/device-plugin.config\":\"no-time-sliced\"}}}}}}'\n\n
    \ # should help auto provisioner\n  oc -n openshift-machine-api \\\n    patch
    \"${MACHINE_SET_TYPE}\" \\\n    --type=merge --patch '{\"spec\":{\"template\":{\"spec\":{\"metadata\":{\"labels\":{\"cluster-api/accelerator\":\"nvidia-gpu\"}}}}}}'\n\n
    \ oc -n openshift-machine-api \\\n    patch \"${MACHINE_SET_TYPE}\" \\\n    --type=merge
    --patch '{\"metadata\":{\"labels\":{\"cluster-api/accelerator\":\"nvidia-gpu\"}}}'\n\n
    \ oc -n openshift-machine-api \\\n    patch \"${MACHINE_SET_TYPE}\" \\\n    --type=merge
    --patch '{\"spec\":{\"template\":{\"spec\":{\"providerSpec\":{\"value\":{\"instanceType\":\"'\"${INSTANCE_TYPE}\"'\"}}}}}}'\n\n#
    \ # fix storage\n\n# cat << YAML > /tmp/patch.yaml\n# spec:\n#   template:\n#
    \    spec:\n#       providerSpec:\n#         value:\n#           blockDevices:\n#
    \            - ebs:\n#                 volumeSize: 120\n#                 volumeType:
    gp3\n# YAML\n\n#   oc -n openshift-machine-api \\\n#     patch \"${MACHINE_SET_TYPE}\"
    \\\n#     --type=merge --patch \"$(cat /tmp/patch.yaml)\"\n}\n\nocp_machineset_taint_gpu(){\n
    \ SHORT_NAME=${1:-g4dn}\n  MACHINE_SET=$(oc -n openshift-machine-api get machinesets.machine.openshift.io
    -o name | grep \"${SHORT_NAME}\" | head -n1)\n\n  echo \"Patching: ${MACHINE_SET}\"\n\n
    \ # taint nodes for gpu-only workloads\n  oc -n openshift-machine-api \\\n    patch
    \"${MACHINE_SET}\" \\\n    --type=merge --patch '{\"spec\":{\"template\":{\"spec\":{\"taints\":[{\"key\":\"nvidia.com/gpu\",\"value\":\"\",\"effect\":\"NoSchedule\"}]}}}}'\n}\n\nocp_machineset_create_autoscale(){\n
    \ MACHINE_MIN=${1:-0}\n  MACHINE_MAX=${2:-4}\n  MACHINE_SETS=${3:-$(oc -n openshift-machine-api
    get machinesets.machine.openshift.io -o name | sed 's@.*/@@' )}\n\n  for machine_set
    in ${MACHINE_SETS}\n  do\ncat << YAML | oc apply -f -\napiVersion: \"autoscaling.openshift.io/v1beta1\"\nkind:
    \"MachineAutoscaler\"\nmetadata:\n  name: \"${machine_set}\"\n  namespace: \"openshift-machine-api\"\nspec:\n
    \ minReplicas: ${MACHINE_MIN}\n  maxReplicas: ${MACHINE_MAX}\n  scaleTargetRef:\n
    \   apiVersion: machine.openshift.io/v1beta1\n    kind: MachineSet\n    name:
    \"${machine_set}\"\nYAML\n  done\n}\n\nocp_aws_cluster_autoscaling(){\n  oc apply
    -k https://github.com/redhat-na-ssa/demo-ai-gitops-catalog/components/cluster-configs/autoscale/overlays/gpus\n\n
    \ ocp_aws_machineset_create_gpu g4dn.4xlarge\n  ocp_machineset_create_autoscale
    0 3\n\n  # scale workers to 1\n  WORKER_MS=\"$(oc -n openshift-machine-api get
    machineset -o name | grep worker | head -n1)\"\n  ocp_machineset_scale 1 \"${WORKER_MS}\"\n\n
    \ ocp_control_nodes_schedulable\n}\n\nocp_machineset_scale(){\n  REPLICAS=${1:-1}\n
    \ MACHINE_SETS=${2:-$(oc -n openshift-machine-api get machineset -o name)}\n\n
    \ # scale workers\n  echo \"${MACHINE_SETS}\" | \\\n    xargs \\\n      oc -n
    openshift-machine-api \\\n      scale --replicas=\"${REPLICAS}\"\n}\n\nocp_control_nodes_not_schedulable(){\n
    \ oc patch schedulers.config.openshift.io/cluster --type merge --patch '{\"spec\":{\"mastersSchedulable\":
    false}}'\n}\n\nocp_control_nodes_schedulable(){\n  oc patch schedulers.config.openshift.io/cluster
    --type merge --patch '{\"spec\":{\"mastersSchedulable\": true}}'\n}\n\nocp_set_scheduler_profile(){\n
    \ SCHED_PROFILE=${1:-LowNodeUtilization}\n\n  # LowNodeUtilization, HighNodeUtilization,
    NoScoring\n  echo \"see https://docs.openshift.com/container-platform/4.16/nodes/scheduling/nodes-scheduler-profiles.html\"\n
    \ echo \"OPTIONS: LowNodeUtilization (default), HighNodeUtilization, NoScoring\"\n
    \ echo \"SCHED_PROFILE: ${SCHED_PROFILE}\"\n\n  oc patch schedulers.config.openshift.io/cluster
    --type merge --patch '{\"spec\":{\"profile\": \"'\"${SCHED_PROFILE}\"'\"}}'\n}\n\n#
    save money in aws\nocp_save_money(){\n\n  # run work on masters\n  ocp_control_nodes_schedulable\n\n
    \ # scale to zero\n  ocp_machineset_scale 0\n\n  # place as many pods on as few
    nodes as possible\n  ocp_set_scheduler_profile HighNodeUtilization\n}\n\nocp_expose_image_registry(){\n
    \ oc patch configs.imageregistry.operator.openshift.io/cluster --type=merge --patch
    '{\"spec\":{\"defaultRoute\":true}}'\n\n  # remove 'default-route-openshift-image-'
    from route\n  HOST=$(oc get route default-route -n openshift-image-registry --template='{{
    .spec.host }}')\n  SHORTER_HOST=$(echo \"${HOST}\" | sed '/host/ s/default-route-openshift-image-//')\n
    \ oc patch configs.imageregistry.operator.openshift.io/cluster --type=merge --patch
    '{\"spec\":{\"host\": \"'\"${SHORTER_HOST}\"'\"}}'\n\n  echo \"OCP image registry
    is available at: ${SHORTER_HOST}\"\n}\n\nocp_release_info(){\n  VERSION=${1:-stable-4.12}\n
    \ echo \"VERSION: ${VERSION}\"\n  curl -sL \"https://mirror.openshift.com/pub/openshift-v4/amd64/clients/ocp/${VERSION}/release.txt\"\n}\n\nocp_run_on_all_nodes(){\n
    \ case $1 in\n    --confirm)\n      shift\n\n      COMMAND=${*:-uptime}\n      ALL_NODES=$(oc
    get nodes --show-kind --no-headers|awk '/node/{print $1}')\n\n      for node in
    ${ALL_NODES}\n        do\n          # wipefs -af /dev/nvme0n1\n          # oc
    debug $node -- chroot /host  bash -c \"$(cat -)\"\n          # shellcheck disable=SC2086\n
    \         oc debug \"$node\" -- chroot /host ${COMMAND}\n      done\n      ;;\n
    \  *)\n      echo \"-------------------------------------------------------------------\"\n
    \     echo \"WARNING. This runs as root on all nodes!\"\n      echo \"You can
    DESTROY ALL DATA, without recovery, if used incorrectly!\"\n      echo \"-------------------------------------------------------------------\"\n
    \     echo \"Usage:\"\n      echo \"  ocp_run_on_all_nodes --confirm < command
    >\"\n  esac\n\n}\n\nocp_upgrade_cluster(){\n  OCP_VERSION=\"${1:-latest}\"\n\n
    \ if [ \"${OCP_VERSION}\" = \"latest\" ]; then\n    oc adm upgrade --to-latest=true\n
    \ else\n    oc adm upgrade --to=\"${OCP_VERSION}\"\n  fi\n}\n\nocp_ack_upgrade_4.13(){\n
    \ oc -n openshift-config patch cm admin-acks --patch '{\"data\":{\"ack-4.12-kube-1.26-api-removals-in-4.13\":\"true\"}}'
    --type=merge\n}\n\nocp_gpu_taint_nodes(){\n  oc adm taint node -l node-role.kubernetes.io/gpu
    nvidia.com/gpu=:NoSchedule --overwrite\n  oc adm drain -l node-role.kubernetes.io/gpu
    --ignore-daemonsets --delete-emptydir-data\n  oc adm uncordon -l node-role.kubernetes.io/gpu\n}\n\nocp_gpu_untaint_nodes(){\n
    \ oc adm taint node -l node-role.kubernetes.io/gpu nvidia.com/gpu=:NoSchedule-\n}\n\nocp_gpu_pretty_label(){\n
    \ oc label node -l nvidia.com/gpu.machine node-role.kubernetes.io/gpu=''\n}\n\nocp_get_pull_secret(){\n
    \ oc -n openshift-config \\\n    get secret/pull-secret \\\n    --template='{{index
    .data \".dockerconfigjson\" | base64decode}}'\n}\n\nocp_mirror_set_pull_secret(){\n
    \ export DOCKER_CONFIG=\"${GIT_ROOT}/scratch\"\n\n  [ -e \"${DOCKER_CONFIG}/config.json\"
    ] && return\n\n  oc -n openshift-config \\\n    extract secret/pull-secret \\\n
    \   --to=- | tee \"${GIT_ROOT}/scratch/pull-secret\" > \"${DOCKER_CONFIG}/config.json\"\n\n
    \ # cat scratch/pull-secret | jq .\n}\n\nocp_mirror_dry_run(){\n  DOC_URL=https://docs.openshift.com/container-platform/4.14/installing/disconnected_install/installing-mirroring-installation-images.html\n\n
    \ echo \"See: ${DOC_URL}\"\n\n  # TIME_STAMP=$(date +%s)\n  TIME_STAMP=$(date
    +%Y.%m.%d)\n\n  LOCAL_SECRET_JSON=${1:-scratch/pull-secret}\n  PRODUCT_REPO=${2:-openshift-release-dev}\n
    \ RELEASE_NAME=${3:-ocp-release}\n  OCP_RELEASE=${4:-4.14.20}\n  ARCHITECTURE=${5:-x86_64}\n\n
    \ LOCAL_REGISTRY=${6:-localhost:5000}\n  LOCAL_REPOSITORY=${7:-ocp4/openshift4}\n\n
    \ REMOVABLE_MEDIA_PATH=scratch/mirror_media\n\n  [ -d \"${REMOVABLE_MEDIA_PATH}\"
    ] || mkdir -p \"${REMOVABLE_MEDIA_PATH}\"\n\n  [ -e \"${DOCKER_CONFIG}/config.json\"
    ] || ocp_mirror_set_pull_secret\n\n  echo oc adm release mirror \\\n    -a \"${LOCAL_SECRET_JSON}\"
    \ \\\n    --from=\"quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE}\"
    \\\n    --to=\"${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}\" \\\n    --to-release-image=\"${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE}\"
    \\\n    --dry-run | \\\n      tee \"${REMOVABLE_MEDIA_PATH}/cmd.${TIME_STAMP}\"
    | \\\n      bash 2>&1 | tee \"${REMOVABLE_MEDIA_PATH}/dryrun.${TIME_STAMP}\"\n\n
    \ # sed '0,/use the following/d ; /^$/d' scratch/dryrun\n\n  echo \"\n  SAVED
    TO: ${REMOVABLE_MEDIA_PATH}/{cmd,dryrun}.${TIME_STAMP}\n  \"\n}\n\nocp_mirror_operator_catalog_list(){\n
    \ VERSION=${1:-4.14}\n  INDEX=${2:-registry.redhat.io/redhat/redhat-operator-index:v${VERSION}}\n\n
    \ which oc-mirror >/dev/null 1>&2 || return\n\n  [ -e \"${DOCKER_CONFIG}/config.json\"
    ] || ocp_mirror_set_pull_secret\n\n  echo \"Please be patient. This process is
    slow...\" 1>&2\n  echo \"oc mirror list operators --catalog ${INDEX}\" 1>&2\n
    \ echo \"INDEX: ${INDEX}\"\n\n  oc mirror list operators --catalog \"${INDEX}\"\n\n
    \ echo \"\"\n}\n\nocp_mirror_operator_catalog_list_all(){\n  VERSION=4.12\n  #
    redhat-operators\n  INDEX_LIST=\"registry.redhat.io/redhat/redhat-operator-index:v${VERSION}\"\n
    \ # certified-operators\n  INDEX_LIST=\"${INDEX_LIST} registry.redhat.io/redhat/certified-operator-index:v${VERSION}\"\n
    \ # redhat-marketplace\n  INDEX_LIST=\"${INDEX_LIST} registry.redhat.io/redhat/redhat-marketplace-index:v${VERSION}\"\n
    \ # community-operators\n  INDEX_LIST=\"${INDEX_LIST} registry.redhat.io/redhat/community-operator-index:v${VERSION}\"\n\n
    \ for index in ${INDEX_LIST}\n  do\n    ocp_mirror_operator_list \"${index}\"\n
    \ done\n}\n\nocp_aro_cluster(){\n  TARGET_NS=kube-system\n  OBJ=secret/azure-credentials\n
    \ echo \"Checking if ${OBJ} exists in ${TARGET_NS} namespace\"\n  oc -n \"${TARGET_NS}\"
    get \"${OBJ}\" -o name > /dev/null 2>&1 || return 1\n  echo \"ARO cluster detected\"\n}\n\nocp_aro_get_key(){\n
    \ # get az creds\n  ocp_aro_cluster || return\n  AZ_TENANT_ID=redhat0.onmicrosoft.com\n\n
    \ AZ_CLIENT_ID=$(oc -n kube-system extract secret/azure-credentials --keys=azure_client_id
    --to=-)\n  AZ_CLIENT_SECRET=$(oc -n kube-system extract secret/azure-credentials
    --keys=azure_client_secret --to=-)\n  AZ_DEFAULT_REGION=$(oc -n kube-system extract
    secret/azure-credentials --keys=azure_region --to=-)\n  AZ_DEFAULT_RG=$(oc -n
    kube-system extract secret/azure-credentials --keys=azure_resourcegroup --to=-)\n
    \ AZ_SUB_ID=$(oc -n kube-system extract secret/azure-credentials --keys=azure_subscription_id
    --to=-)\n  AZ_TENANT_ID=$(oc -n kube-system extract secret/azure-credentials --keys=azure_tenant_id
    --to=-)\n\n  export AZ_CLIENT_ID\n  export AZ_CLIENT_SECRET\n  export AZ_DEFAULT_REGION\n
    \ export AZ_DEFAULT_RG\n  export AZ_SUB_ID\n  export AZ_TENANT_ID\n\n  echo \"AZ_DEFAULT_REGION:
    ${AZ_DEFAULT_REGION}\"\n\n  which az || return 0\n\n  az login --service-principal
    \\\n    -u \"${AZ_CLIENT_ID}\" \\\n    -p \"${AZ_CLIENT_SECRET}\" \\\n    --tenant
    \"${AZ_TENANT_ID}\"\n}\n\nocp_aro_clone_machineset(){\n  [ -z \"${1}\" ] && \\\n
    \ echo \"\n    usage: ocp_aro_clone_machineset < instance type, default Standard_NC64as_T4_v3
    >\n  \"\n\n  INSTANCE_TYPE=${1:-Standard_NC64as_T4_v3}\n  INSTANCE_NAME=$(echo
    \"${INSTANCE_TYPE,,}\" | tr '_' '-')\n  MACHINE_SET=$(oc -n openshift-machine-api
    get machinesets.machine.openshift.io -o name | grep worker | head -n1)\n\n  #
    check for an existing instance machine set\n  if oc -n openshift-machine-api get
    machinesets.machine.openshift.io -o name | grep -q \"${INSTANCE_NAME}\"; then\n
    \   echo \"Exists: machineset - ${INSTANCE_TYPE}\"\n  else\n    echo \"Creating:
    machineset - ${INSTANCE_NAME}\"\n    oc -n openshift-machine-api \\\n      get
    \"${MACHINE_SET}\" -o yaml | \\\n        sed '/machine/ s/-worker/-'\"${INSTANCE_TYPE}\"'/g\n
    \         /name/ s/-worker/-'\"${INSTANCE_NAME}\"'/g\n          s/vmSize.*/vmSize:
    '\"${INSTANCE_TYPE}\"'/\n          s/replicas.*/replicas: 0/' | \\\n      oc apply
    -f -\n  fi\n}\n\nocp_clean_install_pods(){\n  oc delete pod \\\n    -A \\\n    -l
    app=installer\n}\n\nocp_get_kubeconfigs(){\n  # https://rcarrata.com/openshift/regenerate-kubeconfig/\n
    \ # https://gist.githubusercontent.com/rcarrata/016da295c1421cccbfbd66ed9a7922bc/raw/855486c363734892988cdf1b5d0d26ece5e0960a/regenerate-kubeconfig.sh\n
    \ # https://access.redhat.com/solutions/6054981\n  # https://access.redhat.com/solutions/5286371\n
    \ # https://access.redhat.com/solutions/6112601\n\n  oc -n openshift-kube-apiserver
    extract secret/node-kubeconfigs\n}\n\nocp_auth_create_group(){\n  OCP_GROUP=${1:-${DEFAULT_OCP_GROUP}}\n\n
    \ oc get group \"${OCP_GROUP}\" > /dev/null 2>&1 && return\n\necho \"\napiVersion:
    user.openshift.io/v1\nkind: Group\nmetadata:\n  name: ${OCP_GROUP}\n\" | oc apply
    -f-\n\n}\n\nocp_auth_add_to_group(){\n  USER=${1:-admin}\n  OCP_GROUP=${2:-${DEFAULT_OCP_GROUP}}\n\n
    \ ocp_auth_create_group \"${OCP_GROUP}\"\n\n  oc adm groups add-users \\\n  \"${OCP_GROUP}\"
    \"${USER}\"\n}\n\nocp_auth_setup_user(){\n  USER=${1:-admin}\n  PASS=${2:-$(genpass)}\n
    \ OCP_GROUP=${3:-${DEFAULT_OCP_GROUP}}\n\n  htpasswd_add_user \"${USER}\" \"${PASS}\"\n
    \ ocp_auth_add_to_group \"${USER}\" \"${OCP_GROUP}\"\n\n  echo \"\n    run: htpasswd_ocp_set_file\n
    \ \"\n}\n"
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    autoscale: config
  name: job-setup-machineset
  namespace: openshift-machine-api
---
apiVersion: v1
data:
  console-plugin-job.sh: |
    #!/usr/bin/bash

    enable_console_plugin(){
      [ -z "${PLUGIN_NAME}" ] && return 1

      echo "Attempting to enable ${PLUGIN_NAME} plugin"
      echo ""

      # Create the plugins section on the object if it doesn't exist
      if [ -z "$(oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}')" ]; then
        echo "Creating plugins object"
        oc patch consoles.operator.openshift.io cluster --patch '{ "spec": { "plugins": [] } }' --type=merge
      fi

      INSTALLED_PLUGINS=$(oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}')
      echo "Current plugins:"
      echo "${INSTALLED_PLUGINS}"

      if [[ "${INSTALLED_PLUGINS}" == *"${PLUGIN_NAME}"* ]]; then
          echo "${PLUGIN_NAME} is already enabled"
      else
          echo "Enabling plugin: ${PLUGIN_NAME}"
          oc patch consoles.operator.openshift.io cluster --type=json --patch '[{"op": "add", "path": "/spec/plugins/-", "value": "'"${PLUGIN_NAME}"'"}]'
      fi

      sleep 6
      oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}'
    }

    enable_console_plugin
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: job-pipelines-console-plugin
  namespace: openshift-operators
---
apiVersion: v1
data:
  job.sh: |
    #!/usr/bin/bash
    set -e

    TIMEOUT_SECONDS=60

    restart_pods(){
      oc -n redhat-ods-applications \
        delete pods \
        -l deployment=rhods-dashboard
    }

    fix_dashboard_bugs(){
      sleep "${TIMEOUT_SECONDS}"
      restart_pods
    }

    scale_down_dashboard_madness(){

      echo -n 'Waiting for RHOAI dashboard.'
      until oc get -n redhat-ods-applications deployment/rhods-dashboard -o name 2>/dev/null
      do
        echo -n .
        sleep 5
      done; echo

      oc -n redhat-ods-applications \
        scale deployment/rhods-dashboard \
        --replicas=2
    }

    scale_down_dashboard_madness
    fix_dashboard_bugs
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: fix-dashboard-magic
  namespace: redhat-ods-applications
---
apiVersion: v1
data:
  CULL_IDLE_TIME: "24"
  ENABLE_CULLING: "true"
  IDLENESS_CHECK_PERIOD: "1"
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  labels:
    opendatahub.io/dashboard: "true"
  name: notebook-controller-culler-config
  namespace: redhat-ods-applications
---
apiVersion: v1
data:
  segmentKeyEnabled: "false"
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  labels:
    app.kubernetes.io/part-of: segment-io
    app.opendatahub.io/segment-io: "true"
  name: odh-segment-key-config
  namespace: redhat-ods-applications
---
apiVersion: v1
data:
  job.sh: |
    #!/usr/bin/bash
    # shellcheck disable=SC2119,SC2120
    set -e

    TIMEOUT_SECONDS=60

    approve_installplan(){
      echo -n 'Waiting for RHOAI install plan...'
      until oc -n redhat-ods-operator get installplan -l operators.coreos.com/rhods-operator.redhat-ods-operator -o name >/dev/null 2>&1
      do
        echo -n .
        sleep 5
      done; echo

      INSTALL_PLAN=$(oc -n redhat-ods-operator get installplan -l operators.coreos.com/rhods-operator.redhat-ods-operator -o name)
      oc -n redhat-ods-operator \
        patch "${INSTALL_PLAN}" \
        --type=merge --patch '{"spec":{"approved":true}}'
    }

    patch_approval(){
      APPROVAL=${1:-Automatic}

      echo -n 'Waiting for RHOAI subscription...'
      until oc get -n redhat-ods-operator subscription rhods-operator -o name >/dev/null 2>&1
      do
        echo -n .
        sleep 5
      done; echo

      oc -n redhat-ods-operator \
        patch subscription rhods-operator \
        --type=merge --patch '{"spec":{"installPlanApproval":"'"${APPROVAL}"'"}}'
    }

    wait_for_service_mesh(){
      echo "Checking status of all service_mesh pre-reqs"

      SERVICEMESH_RESOURCES=(
        crd/knativeservings.operator.knative.dev:condition=established
        crd/servicemeshcontrolplanes.maistra.io:condition=established
        crd/servicemeshmembers.maistra.io:condition=established
      )

      for crd in "${SERVICEMESH_RESOURCES[@]}"
      do
        RESOURCE=$(echo "$crd" | cut -d ":" -f 1)
        CONDITION=$(echo "$crd" | cut -d ":" -f 2)

        echo "Waiting for ${RESOURCE} state to be ${CONDITION}..."
        oc wait --for="${CONDITION}" "${RESOURCE}" --timeout="${TIMEOUT_SECONDS}s" >/dev/null 2>&1
      done
    }

    wait_for_service_mesh
    patch_approval
    approve_installplan
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: approve-after-servicemesh
  namespace: redhat-ods-operator
---
apiVersion: v1
data:
  job.sh: |
    #!/usr/bin/bash
    set -e

    TIMEOUT_SECONDS=60

    wait_for_service_mesh(){
      echo "Checking status of all service_mesh pre-reqs"

      SERVICEMESH_RESOURCES=(
        crd/knativeservings.operator.knative.dev:condition=established
        crd/servicemeshcontrolplanes.maistra.io:condition=established
      )

      for crd in "${SERVICEMESH_RESOURCES[@]}"
      do
        RESOURCE=$(echo "$crd" | cut -d ":" -f 1)
        CONDITION=$(echo "$crd" | cut -d ":" -f 2)

        echo "Waiting for ${RESOURCE} state to be ${CONDITION}..."
        oc wait --for="${CONDITION}" "${RESOURCE}" --timeout="${TIMEOUT_SECONDS}s"
      done
    }

    wait_for_service_mesh
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: wait-for-servicemesh
  namespace: redhat-ods-operator
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    service.alpha.openshift.io/serving-cert-secret-name: plugin-serving-cert
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
spec:
  ports:
  - name: 9443-tcp
    port: 9443
    protocol: TCP
    targetPort: 9443
  selector:
    app.kubernetes.io/name: console-plugin-nvidia-gpu
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    app.openshift.io/runtime-namespace: console-plugin-nvidia-gpu
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: console-plugin-nvidia-gpu
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
      labels:
        app.kubernetes.io/name: console-plugin-nvidia-gpu
    spec:
      containers:
      - image: quay.io/edge-infrastructure/console-plugin-nvidia-gpu:latest
        imagePullPolicy: Always
        name: console-plugin-nvidia-gpu
        ports:
        - containerPort: 9443
          protocol: TCP
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
        volumeMounts:
        - mountPath: /var/serving-cert
          name: plugin-serving-cert
          readOnly: true
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      securityContext:
        runAsNonRoot: true
      volumes:
      - name: plugin-serving-cert
        secret:
          defaultMode: 420
          secretName: plugin-serving-cert
      - configMap:
          defaultMode: 420
          name: nginx-conf
        name: nginx-conf
---
apiVersion: autoscaling.openshift.io/v1
kind: ClusterAutoscaler
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    autoscale: config
  name: default
  namespace: openshift-machine-api
spec:
  podPriorityThreshold: -10
  resourceLimits:
    cores:
      max: 128
      min: 0
    gpus:
    - max: 8
      min: 0
      type: nvidia.com/gpu
    - max: 1
      min: 0
      type: amd.com/gpu
    maxNodesTotal: 10
    memory:
      max: 512
      min: 0
  scaleDown:
    delayAfterAdd: 5m
    delayAfterDelete: 1m
    delayAfterFailure: 30s
    enabled: true
    unneededTime: 5m
    utilizationThreshold: "0.7"
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  generateName: job-aws-gpu-machineset-
  name: job-aws-gpu-machineset
  namespace: nvidia-gpu-operator
spec:
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/job.sh
        env:
        - name: INSTANCE_TYPE
          value: g4dn.4xlarge
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: registry.redhat.io/openshift4/ose-cli
        name: job-aws-gpu-machineset
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: job-aws-gpu-machineset
      serviceAccountName: job-aws-gpu-machineset
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          defaultMode: 493
          name: job-aws-gpu-machineset
        name: scripts
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "10"
  generateName: job-gpu-console-plugin-
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
spec:
  backoffLimit: 4
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/console-plugin-job.sh
        env:
        - name: PLUGIN_NAME
          value: console-plugin-nvidia-gpu
        image: registry.redhat.io/openshift4/ose-cli
        name: minion
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: job-gpu-console-plugin
      serviceAccountName: job-gpu-console-plugin
      volumes:
      - configMap:
          defaultMode: 493
          name: job-gpu-console-plugin
        name: scripts
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    autoscale: config
  name: job-setup-machineset
  namespace: openshift-machine-api
spec:
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/job.sh
        env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MACHINE_MIN
          value: "0"
        - name: MACHINE_MAX
          value: "4"
        image: registry.redhat.io/openshift4/ose-cli
        name: minion
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: job-setup-machineset
      serviceAccountName: job-setup-machineset
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          defaultMode: 493
          name: job-setup-machineset
        name: scripts
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "10"
  name: job-pipelines-console-plugin
  namespace: openshift-operators
spec:
  backoffLimit: 4
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/console-plugin-job.sh
        env:
        - name: PLUGIN_NAME
          value: pipelines-console-plugin
        image: registry.redhat.io/openshift4/ose-cli
        name: minion
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: job-pipelines-console-plugin
      serviceAccountName: job-pipelines-console-plugin
      volumes:
      - configMap:
          defaultMode: 493
          name: job-pipelines-console-plugin
        name: scripts
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
    argocd.argoproj.io/sync-wave: "11"
  name: fix-dashboard-magic
  namespace: redhat-ods-applications
spec:
  backoffLimit: 4
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
        argocd.argoproj.io/sync-options: ServerSideApply=true
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/job.sh
        image: registry.redhat.io/openshift4/ose-cli
        name: minion
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: fix-dashboard-magic
      serviceAccountName: fix-dashboard-magic
      volumes:
      - configMap:
          defaultMode: 493
          name: fix-dashboard-magic
        name: scripts
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: approve-after-servicemesh
  namespace: redhat-ods-operator
spec:
  backoffLimit: 4
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/job.sh
        image: registry.redhat.io/openshift4/ose-cli
        name: minion
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: approve-after-servicemesh
      serviceAccountName: approve-after-servicemesh
      volumes:
      - configMap:
          defaultMode: 493
          name: approve-after-servicemesh
        name: scripts
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
    argocd.argoproj.io/sync-wave: "10"
  name: wait-for-servicemesh
  namespace: redhat-ods-operator
spec:
  backoffLimit: 4
  template:
    metadata:
      annotations:
        argocd.argoproj.io/hook: PreSync
        argocd.argoproj.io/sync-options: ServerSideApply=true
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/job.sh
        image: registry.redhat.io/openshift4/ose-cli
        name: minion
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: wait-for-servicemesh
      serviceAccountName: wait-for-servicemesh
      volumes:
      - configMap:
          defaultMode: 493
          name: wait-for-servicemesh
        name: scripts
---
apiVersion: console.openshift.io/v1
kind: ConsoleLink
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    source: https://github.com/redhat-na-ssa/demo-ai-catalog.git
  labels:
    demo: catalog
  name: github-catalog
spec:
  applicationMenu:
    imageURL: /static/assets/public/imgs/logos/github.svg
    section: Git Repos
  href: https://github.com/redhat-na-ssa/demo-ai-gitops-catalog
  location: ApplicationMenu
  text: GitHub - GitOps Catalog
---
apiVersion: console.openshift.io/v1
kind: ConsoleLink
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: Prune=true
    source: https://github.com/redhat-na-ssa/demo-ai-catalog.git
  labels:
    demo: catalog
  name: github-ssa
spec:
  applicationMenu:
    imageURL: /static/assets/public/imgs/logos/github.svg
    section: Git Repos
  href: https://github.com/redhat-na-ssa
  location: ApplicationMenu
  text: GitHub - NA SSA
---
apiVersion: console.openshift.io/v1
kind: ConsoleLink
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: Prune=true
    source: https://github.com/redhat-na-ssa/demo-ai-catalog.git
  labels:
    demo: catalog
  name: help-link
spec:
  href: https://github.com/redhat-na-ssa/demo-ai-gitops-catalog/issues
  location: HelpMenu
  text: Github - Open Issue
---
apiVersion: console.openshift.io/v1
kind: ConsoleNotification
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: Prune=true
    source: https://github.com/redhat-na-ssa/demo-ai-catalog.git
  labels:
    demo: catalog
  name: banner-cluster
spec:
  backgroundColor: '#0066FF'
  color: '#FFF'
  location: BannerBottom
  text: This cluster was configured via the AI GitOps catalog
---
apiVersion: console.openshift.io/v1
kind: ConsoleNotification
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    source: https://github.com/redhat-na-ssa/demo-ai-catalog.git
  labels:
    demo: catalog
  name: banner-demo
spec:
  backgroundColor: '#9F0000'
  color: '#FFF'
  location: BannerTop
  text: 'DEMO: Red Hat OpenShift AI (RHOAI)'
---
apiVersion: console.openshift.io/v1alpha1
kind: ConsolePlugin
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
spec:
  displayName: Console Plugin NVIDIA GPU Template
  service:
    basePath: /
    name: console-plugin-nvidia-gpu
    namespace: nvidia-gpu-operator
    port: 9443
---
apiVersion: dashboard.opendatahub.io/v1
kind: AcceleratorProfile
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: nvidia
  namespace: redhat-ods-applications
spec:
  description: Default Nvidia GPU Profile
  displayName: Nvidia GPU
  enabled: true
  identifier: nvidia.com/gpu
  tolerations:
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Exists
---
apiVersion: datasciencecluster.opendatahub.io/v1
kind: DataScienceCluster
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: default-dsc
  namespace: redhat-ods-applications
spec:
  components:
    codeflare:
      managementState: Managed
    dashboard:
      managementState: Managed
    datasciencepipelines:
      managementState: Managed
    kserve:
      managementState: Managed
      serving:
        ingressGateway:
          certificate:
            type: SelfSigned
        managementState: Managed
        name: knative-serving
    kueue:
      managementState: Managed
    modelmeshserving:
      managementState: Managed
    ray:
      managementState: Managed
    trainingoperator:
      managementState: Managed
    workbenches:
      managementState: Managed
---
apiVersion: dscinitialization.opendatahub.io/v1
kind: DSCInitialization
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: default-dsci
  namespace: redhat-ods-applications
spec:
  applicationsNamespace: redhat-ods-applications
  monitoring:
    managementState: Managed
    namespace: redhat-ods-monitoring
  serviceMesh:
    auth:
      audiences:
      - https://kubernetes.default.svc
    controlPlane:
      metricsCollection: Istio
      name: data-science-smcp
      namespace: istio-system
    managementState: Managed
  trustedCABundle:
    customCABundle: ""
    managementState: Managed
---
apiVersion: nfd.openshift.io/v1
kind: NodeFeatureDiscovery
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: nfd-instance
  namespace: openshift-nfd
spec:
  instance: ""
  operand:
    image: registry.redhat.io/openshift4/ose-node-feature-discovery:latest
    servicePort: 12000
  topologyUpdater: false
  workerConfig:
    configData: |
      core:
        sleepInterval: 60s
      sources:
        pci:
          deviceClassWhitelist:
            - "0200"
            - "03"
            - "12"
          deviceLabelFields:
            - "vendor"
---
apiVersion: nvidia.com/v1
kind: ClusterPolicy
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: gpu-cluster-policy
  namespace: nvidia-gpu-operator
spec:
  daemonsets:
    rollingUpdate:
      maxUnavailable: "1"
    tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
    updateStrategy: RollingUpdate
  dcgm:
    enabled: true
  dcgmExporter:
    config:
      name: console-plugin-nvidia-gpu
    enabled: true
    serviceMonitor:
      enabled: true
  devicePlugin:
    config:
      default: time-sliced
      name: device-plugin-config
    enabled: true
  driver:
    certConfig:
      name: ""
    enabled: true
    kernelModuleConfig:
      name: ""
    licensingConfig:
      configMapName: ""
      nlsEnabled: false
    repoConfig:
      configMapName: ""
    upgradePolicy:
      autoUpgrade: true
      drain:
        deleteEmptyDir: false
        enable: false
        force: false
        timeoutSeconds: 300
      maxParallelUpgrades: 1
      maxUnavailable: 25%
      podDeletion:
        deleteEmptyDir: false
        force: false
        timeoutSeconds: 300
      waitForCompletion:
        timeoutSeconds: 0
    virtualTopology:
      config: ""
  gds:
    enabled: false
  gfd:
    enabled: true
  mig:
    strategy: single
  migManager:
    enabled: true
  nodeStatusExporter:
    enabled: true
  operator:
    defaultRuntime: crio
    initContainer: {}
    use_ocp_driver_toolkit: true
  sandboxDevicePlugin:
    enabled: true
  sandboxWorkloads:
    defaultWorkload: container
    enabled: false
  toolkit:
    enabled: true
  validator:
    plugin:
      env:
      - name: WITH_WORKLOAD
        value: "true"
  vfioManager:
    enabled: true
  vgpuDeviceManager:
    enabled: true
  vgpuManager:
    enabled: false
---
apiVersion: opendatahub.io/v1alpha
kind: OdhDashboardConfig
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-options: ServerSideApply=true
  name: odh-dashboard-config
  namespace: redhat-ods-applications
spec:
  dashboardConfig:
    disableBiasMetrics: true
    disableKServe: false
    disableModelMesh: false
  groupsConfig:
    adminGroups: rhods-admins
    allowedGroups: system:authenticated
  modelServerSizes:
  - name: Small
    resources:
      limits:
        cpu: "2"
        memory: 8Gi
      requests:
        cpu: "1"
        memory: 4Gi
  - name: Medium
    resources:
      limits:
        cpu: "8"
        memory: 10Gi
      requests:
        cpu: "4"
        memory: 8Gi
  - name: Large
    resources:
      limits:
        cpu: "10"
        memory: 20Gi
      requests:
        cpu: "6"
        memory: 16Gi
  notebookController:
    enabled: true
    pvcSize: 20Gi
  notebookSizes:
  - name: Small
    resources:
      limits:
        cpu: "2"
        memory: 8Gi
      requests:
        cpu: "1"
        memory: 8Gi
  - name: Medium
    resources:
      limits:
        cpu: "6"
        memory: 24Gi
      requests:
        cpu: "3"
        memory: 24Gi
  - name: Large
    resources:
      limits:
        cpu: "14"
        memory: 56Gi
      requests:
        cpu: "7"
        memory: 56Gi
  - name: X Large
    resources:
      limits:
        cpu: "30"
        memory: 120Gi
      requests:
        cpu: "15"
        memory: 120Gi
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: gpu-operator-certified
  namespace: nvidia-gpu-operator
spec:
  targetNamespaces:
  - nvidia-gpu-operator
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: nfd
  namespace: openshift-nfd
spec:
  targetNamespaces:
  - openshift-nfd
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: serverless-operator
  namespace: openshift-serverless
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: rhods-operator
  namespace: redhat-ods-operator
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: gpu-operator-certified
  namespace: nvidia-gpu-operator
spec:
  channel: stable
  installPlanApproval: Automatic
  name: gpu-operator-certified
  source: certified-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: nfd
  namespace: openshift-nfd
spec:
  channel: stable
  installPlanApproval: Automatic
  name: nfd
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: authorino-operator
  namespace: openshift-operators
spec:
  channel: tech-preview-v1
  installPlanApproval: Automatic
  name: authorino-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: openshift-pipelines-operator-rh
  namespace: openshift-operators
spec:
  channel: latest
  installPlanApproval: Automatic
  name: openshift-pipelines-operator-rh
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: servicemeshoperator
  namespace: openshift-operators
spec:
  channel: stable
  installPlanApproval: Automatic
  name: servicemeshoperator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: serverless-operator
  namespace: openshift-serverless
spec:
  channel: stable
  installPlanApproval: Automatic
  name: serverless-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
  name: rhods-operator
  namespace: redhat-ods-operator
spec:
  channel: stable
  installPlanApproval: Manual
  name: rhods-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: template.openshift.io/v1
kind: Template
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    opendatahub.io/apiProtocol: REST
    opendatahub.io/modelServingSupport: '["multi"]'
  labels:
    opendatahub.io/dashboard: "true"
  name: trition-serving-runtime
  namespace: redhat-ods-applications
objects:
- apiVersion: serving.kserve.io/v1alpha1
  kind: ServingRuntime
  metadata:
    annotations:
      maxLoadingConcurrency: "2"
      openshift.io/display-name: Triton runtime 23.10
    labels:
      name: triton-23.10
    name: triton-23.10
  spec:
    builtInAdapter:
      memBufferBytes: 134217728
      modelLoadingTimeoutMillis: 90000
      runtimeManagementPort: 8001
      serverType: triton
    containers:
    - args:
      - -c
      - 'mkdir -p /models/_triton_models; chmod 777 /models/_triton_models; exec tritonserver
        "--model-repository=/models/_triton_models" "--model-control-mode=explicit"
        "--strict-model-config=false" "--strict-readiness=false" "--allow-http=true"
        "--allow-sagemaker=false" '
      command:
      - /bin/sh
      image: nvcr.io/nvidia/tritonserver:23.10-py3
      livenessProbe:
        exec:
          command:
          - curl
          - --fail
          - --silent
          - --show-error
          - --max-time
          - "9"
          - http://localhost:8000/v2/health/live
        initialDelaySeconds: 5
        periodSeconds: 30
        timeoutSeconds: 10
      name: triton
      resources:
        limits:
          cpu: "5"
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 1Gi
      volumeMounts:
      - mountPath: /dev/shm
        name: shm
    grpcDataEndpoint: port:8001
    grpcEndpoint: port:8085
    multiModel: true
    protocolVersions:
    - grpc-v2
    supportedModelFormats:
    - autoSelect: true
      name: keras
      version: "2"
    - autoSelect: true
      name: onnx
      version: "1"
    - autoSelect: true
      name: pytorch
      version: "1"
    - autoSelect: true
      name: tensorflow
      version: "1"
    - autoSelect: true
      name: tensorflow
      version: "2"
    - autoSelect: true
      name: tensorrt
      version: "7"
    volumes:
    - emptyDir:
        medium: Memory
        sizeLimit: 2Gi
      name: shm
